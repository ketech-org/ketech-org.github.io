[{
  "section": "Products",
  "slug": "/products/watchless/",
  "title": "WatchLess",
  "description": "Watch less. TL;DR. Video summaries.",
  "date": "December 29, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "",
  "tags": "",
  "content":" Too many long videos and not enough time?\nWatchLess helps you understand videos without watching them. Just share a video link to WatchLess and get a clear, concise TL;DR in seconds. No setup required. WatchLess turns lengthy videos — lectures, interviews, podcasts, and explainers — into easy-to-read summaries so you can focus on what matters. Key Features Summarises videos into short, clear overviews Works directly from the system Share Sheet No configuration, no accounts, no friction Clean, readable summaries that are easy to scan Helps you decide quickly if a video is worth watching Perfect for Students reviewing lectures Professionals catching up on talks or interviews Researchers skimming long-form content Anyone who wants the key points without the runtime Watch less. Know more. "},{
  "section": "Products",
  "slug": "/products/tempoblocks/",
  "title": "TempoBlocks",
  "description": "Metronome. Code. Play.",
  "date": "December 29, 2023",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "",
  "tags": "",
  "content":"The Product TempoBlocks is an intuitive metronome that goes beyond keeping time. It combines a clean, friendly interface with a block-based language that lets users build, customize, and explore rhythms through visual programming.\nKey Features Elegant bar wheel: Shows timing and beat strength at a glance. Simple, direct controls: Effortless tempo settings. Engaging sound sets: Useful presets for quick setup. Accurate timing: High-quality audio engine. Visual cues: Helps learners understand beat patterns and accents. Custom rhythm blocks: Visual domain-specific language (\u0026lsquo;Tempo blocks\u0026rsquo;). Ad-free: Safe, distraction-free learning. The Engine: DesignForge \u0026ldquo;We didn\u0026rsquo;t just write a metronome. We forged a design system.\u0026rdquo;\nTempoBlocks is the first consumer product built on DesignForge—our internal study on \u0026ldquo;Engineering Beauty.\u0026rdquo; The complex bar wheel visualizer started as an isolated study in the Forge, perfected before it ever reached the iOS app.\nRead the full engineering story behind DesignForge →\n"},{
  "section": "Products",
  "slug": "/products/wen/",
  "title": "Project Wen",
  "description": "Illuminating Ancient Verse.",
  "date": "January 1, 2026",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "",
  "tags": "",
  "content":"Status: Active R\u0026amp;D / Coming 2026\nProject Wen (文) is an initiative to reconnect with the soul of Ancient Chinese poetry.\nIn a world of abundant information, Wen helps us slow down and illuminate, feel, and savor the profound beauty of classical verse—transforming static text into a living, resonant experience.\nR\u0026amp;D Focus Areas Deciphering Flavor: Moving beyond literal translation to capture the wei (taste) and emotional resonance of the original work. Contextual Guides: AI aids that provide historical and cultural depth, acting as a bridge across millennia rather than just a dictionary. Hyper-Local AI: Privacy-first architecture running complex inference including vision and text generation entirely on-device or on private infrastructure. Engineering Highlights Polyglot Architecture: High-performance Go nodes orchestrating local LLM runtimes. Offline-First: Fully reproducible data pipelines built with DVC. Multimodal Generation: Integrated ComfyUI workflows for generative visualizations that accompany the verse. "},{
  "section": "Engineering",
  "slug": "/engineering/design-forge/",
  "title": "DesignForge: Engineering Beauty at Scale",
  "description": "",
  "date": "January 3, 2026",
  "image": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n  \n  \n\n\n  \n",
  "imageSM": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n  \n  \n\n\n  \n",
  "searchKeyword": "",
  "categories": "",
  "tags": "Design Systems, Vite, React, Frontend Architecture",
  "content":"Executive Summary In the era of AI-assisted development, generating functional code has become trivial. However, bridging the gap between \u0026ldquo;functional\u0026rdquo; and \u0026ldquo;beautiful, production-grade\u0026rdquo; remains a significant challenge. DesignForge was created to address this specific need. It is not just a component library, but a design-quality repository—a curated collection of high-aesthetic UI exemplars, micro-interactions, and layout patterns designed to serve as style anchors for modern engineering teams across Web and SwiftUI.\nThe Challenge: Functionality vs. Aesthetics Modern Large Language Models (LLMs) are exceptional at logic and structure but often struggle with the subtle nuances that make a user interface feel \u0026ldquo;premium.\u0026rdquo;\nGeneric Designs: AI tends to default to safe, standard Bootstrap-like layouts. Inconsistent Visuals: Maintaining a cohesive style across disparate generated components is difficult. Lack of \u0026ldquo;Soul\u0026rdquo;: Subtle animations, precise spacing, and cohesive color theory are often lost in translation. We needed a way to inject \u0026ldquo;soul\u0026rdquo; back into the development process—a source of truth that defines what good looks like so that both engineers and AI agents can replicate it.\nThe Solution: A \u0026ldquo;Design Forge\u0026rdquo; DesignForge acts as a workshop for visual engineering. Instead of rigid, monolithic components, it provides studies—self-contained experiments in interaction and style. The project is dual-platform by design, supporting seamless style and design transfer between Web and SwiftUI. Because each study operates as an isolated small context, porting visual concepts across platforms becomes significantly easier.\n\u0026ldquo;Think of it as a design forge—a workshop of crafted patterns ready to be reshaped into new creations.\u0026rdquo;\nKey capabilities include:\nPolished UI Studies: Complete, high-fidelity implementations of complex UI concepts. Shared Workbench: A unified environment to develop, test, and showcase individual studies. AI-Ready References: Clean, semantic, and isolated code patterns that are easy for AI context windows to digest and adapt. Technical Architecture Built to scale, DesignForge leverages a modern monorepo structure to keep studies independent yet interconnected.\nMonorepo Layout The project is organized to separate concerns effectively:\nweb/: The top-level web portal for listing, previewing, and navigating all web components, including the shared workbench shell. studies/: A collection of isolated Vite apps. Each study is its own workspace, ensuring zero side-effects between experiments. mac/: A shared Swift package and workbench shell for macOS/iOS study projects. Key Features 1. Isolated Workspaces Each visual study runs in its own Vite sandbox. This encourages experimentation with heavy libraries or unique CSS approaches without bloating the main application bundle.\n2. The Dual-Platform Workbench The workbench acts as the common scaffolding for every study, standardized across both Web and macOS.\nIn the codebase, this is implemented via a shared WorkbenchShell component.\nKey capabilities provided by the shell:\nUnified Theming: Automatically propagates light/dark mode and accent colors. Precision Scaling: On the web, it injects a --df-scale CSS variable to allow pixel-perfect zooming and inspection. Layout Enforcement: Ensures a consistent 2 or 3-column layout (Control, Dissecting, Review) across all studies. 3. Rapid Scaffolding Built-in tooling (npm run new-study) allows for the instant creation of new study environments, encouraging engineers to spin up a new \u0026ldquo;canvas\u0026rdquo; for every new idea, rather than hacking on existing code.\n4. The \u0026ldquo;Forge\u0026rdquo; Workflow Once study projects are refined, they can be \u0026ldquo;forged\u0026rdquo; into larger, reusable projects or widgets. A prime example is the bar wheel for the iOS app TempoBlocks, which began as an isolated study in this repository before being forged into a shipping feature.\nConclusion DesignForge represents a shift in how we approach frontend engineering. By treating UI patterns as first-class citizens and providing a dedicated infrastructure for their development, we empower engineers to move beyond \u0026ldquo;good enough.\u0026rdquo; It is a testament to the belief that with the right tools, engineering and beauty are not mutually exclusive—they are complementary forces.\n"},{
  "section": "Engineering",
  "slug": "/engineering/first-post/",
  "title": "Welcome to K&amp;E Tech",
  "description": "An intro to our new website and direction.",
  "date": "May 20, 2024",
  "image": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n  \n  \n    \n      \n    \n\n\n    \n    \n\n\n    \n    \n      \n      \n    \n    \n    \n\n\n    \n    \n      \n      \n        \n        \n        \n        \n        \n        \n\n\n        \n        \n\n\n        \u003cimg\n          \n            src=\"/images/engineering/covers/first-post-cover_hu_f7407aec5436f6fb.webp\" loading=\"lazy\" decoding=\"async\"\n          \n\n          alt=\"\"\n          class=\"  img\"\n          width=\"420\"\n          height=\"420\"\n          onerror=\"this.onerror='null';this.src='\\/images\\/engineering\\/covers\\/first-post-cover_hu_ff859551889d4be8.png';\" /\u003e\n\n        \n      \n      \n    \n    \n  \n\n\n  \n",
  "imageSM": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n  \n  \n    \n      \n    \n\n\n    \n    \n\n\n    \n    \n      \n      \n    \n    \n    \n\n\n    \n    \n      \n      \n        \n        \n        \n        \n        \n        \n          \n          \n          \n          \n        \n\n\n        \n        \n\n\n        \u003cimg\n          \n            src=\"/images/engineering/covers/first-post-cover_hu_94d3b93d5c19345.webp\" loading=\"lazy\" decoding=\"async\"\n          \n\n          alt=\"\"\n          class=\"  img\"\n          width=\"100\"\n          height=\"100\"\n          onerror=\"this.onerror='null';this.src='\\/images\\/engineering\\/covers\\/first-post-cover_hu_ce0b7f8890aec862.png';\" /\u003e\n\n        \n      \n      \n    \n    \n  \n\n\n  \n",
  "searchKeyword": "",
  "categories": "Company News",
  "tags": "Redesign, Announcement",
  "content":"Welcome! We are excited to unveil our refreshed website and updated service offerings. K\u0026amp;E Tech has always been about quality and innovation, and our new digital home reflects that.\nWe have expanded our focus to not only build great products of our own but to also offer consulting services to help others achieve the same level of engineering excellence.\nStay tuned for more updates and technical deep dives!\n"},{
  "section": "Engineering",
  "slug": "/engineering/go-pattern-hybrid-handler/",
  "title": "Go Pattern: Hybrid Handler",
  "description": "",
  "date": "April 22, 2023",
  "image": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n  \n  \n    \n      \n    \n\n\n    \n    \n\n\n    \n    \n      \n      \n    \n    \n    \n\n\n    \n    \n      \n      \n        \n        \n        \n        \n        \n        \n\n\n        \n        \n\n\n        \u003cimg\n          \n            src=\"/images/custom/misc/hybrid-handler-hero_hu_d26bbf26fc1de6ab.webp\" loading=\"lazy\" decoding=\"async\"\n          \n\n          alt=\"\"\n          class=\"  img\"\n          width=\"420\"\n          height=\"420\"\n          onerror=\"this.onerror='null';this.src='\\/images\\/custom\\/misc\\/hybrid-handler-hero_hu_49de5e7c33a80467.jpg';\" /\u003e\n\n        \n      \n      \n    \n    \n  \n\n\n  \n",
  "imageSM": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n  \n  \n    \n      \n    \n\n\n    \n    \n\n\n    \n    \n      \n      \n    \n    \n    \n\n\n    \n    \n      \n      \n        \n        \n        \n        \n        \n        \n          \n          \n          \n          \n        \n\n\n        \n        \n\n\n        \u003cimg\n          \n            src=\"/images/custom/misc/hybrid-handler-hero_hu_fceb29293f6fe5c.webp\" loading=\"lazy\" decoding=\"async\"\n          \n\n          alt=\"\"\n          class=\"  img\"\n          width=\"100\"\n          height=\"100\"\n          onerror=\"this.onerror='null';this.src='\\/images\\/custom\\/misc\\/hybrid-handler-hero_hu_9ecddec3b7522f0b.jpg';\" /\u003e\n\n        \n      \n      \n    \n    \n  \n\n\n  \n",
  "searchKeyword": "",
  "categories": "",
  "tags": "Go, pattern, hybrid runner, runner",
  "content":"Overview In today\u0026rsquo;s high-performance and concurrent computing environments, effectively processing a stream of messages using a mix of purely computational functions and remote procedure calls has become a significant challenge. The Go programming language is designed to handle concurrency well, but when it comes to managing a hybrid load, even Go can struggle to achieve optimal CPU utilization. In this article, we will discuss the Hybrid Handler pattern, an efficient and unified approach to address this challenge.\nThe problem Assuming we have a stream of incoming messages and we need to process them with a list of handlers, aggregate the results and send the output downstream.\nIf all the handlers are only purely local computations, then an implementation like below already meets the basic functional and performance requirements.\ntype Processor struct { handlers SyncHandler } type SyncHandler interface { Handle(ctx context.Context, message Message) (Result, error) } func (p *Processor) ProcessMessage(ctx context.Context, message Message) error { output := NewOutput() for _, handler := range p.handlers { result, err := handler.Handle(ctx, message) if err != nil { return err } output.Add(result) } return p.SendOutput(output) } e.g. With an 8-core CPU, we can simply initialise 8 Processor objects and run them in 8 goroutines, which can make full use of the hardware easily. (error handling is omitted here)\nfor i := 0; i \u0026lt; numCPU; i++ { go func() { processor := NewProcessor() for message := range inputChan { processor.ProcessMessage(ctx, message) } }() } However, if the processing logic involves a mix of local computations and remote procedure calls, it becomes more difficult to process a high volume of messages in a timely and efficient manner. If the processor still handles messages one by one, it must wait for all handlers to complete before outputting the corresponding result. However, The added I/O roundtrip delay for each message will be so high that the CPU cores stay idle most of the time.\nTo mitigate this issue, one could attempt to saturate the CPU with brute force, parallelizing the processors with even more goroutines, as in most microservices written in Go, where one goroutine is used to handle one incoming request. While this might work well enough for an IO-bound application or when the traffic is low, it can penalize the performance significantly when all or most of the handlers are pure computations due to the relative costs of channel message passing and goroutine scheduling compared to the computations themselves.\nAnother feasible but more ad-hoc solution is just to separate purely computational handlers from remote handlers into two groups, and execute them differently, which could potentially remove the penalty on pure computations. However, how to wait for all the results is still a problem and two separate groups add more complexity to both the start and finish of those functions.\nWhat we need here is an abstraction that unifies local and remote handlers without the overhead of goroutines and channels. This would allow purely computational handlers to achieve bare metal speed while remote handlers don\u0026rsquo;t block unnecessarily.\nThe Hybrid Handler pattern type Handler interface { Handle( ctx context.Context, message Message, returnResult ReturnResultFunc, ) error type ReturnResultFunc func(ctx context.Context, result Result) error The key to addressing these challenges lies in an interface method that provides a callback parameter returnResult for returning the result, which allows the implementation of the interface to be either a synchronous pure computation or an asynchronous IO operation without introducing much overhead.\nIs it just a function with a callback?\nYes, at first glance, it might look not only trivial but also unidiomatic in Go, but looking closely, we will find that it is a simple and natural solution to the problem at hand and makes a lot of sense.\nThe new processor With the Handler interface above, the Processor can be re-implemented as below.\nOn arrival of each result, the output can decrement a counter atomically to determine if it\u0026rsquo;s ready to be sent downstream. This operation adds much less overhead than the brute force way of adding many goroutines.\ntype Processor struct { handlers Handler } type Output struct { handlerCount int64 processor *Processor } func (p *Processor) NewOutput(handlerCount int) *Output { return \u0026amp;Output{ HandlerCount: handlerCount, processor: p, } } func (p *Processor) ProcessMessage(ctx context.Context, message Message) error { output := p.NewOutput(len(p.handlers)) for _, handler := range p.handlers { result, err := handler.Handle(ctx, message, output.Add) if err != nil { return err } } return nil } func (o *Output) Add(ctx context.Context, result Result) error // add the result to the output // ...... // check if it\u0026#39;s the result of the the last handler if atomic.AddInt64(\u0026amp;h.row.pendingCategories, -1) \u0026gt; 0 { return nil // not the last one } // is the last one return p.processor.SendOutput(o) } Synchronous handlers It is almost trivial to write an adapter from any synchronous handler to the Handler interface above, and the overhead is just one extra interface method call.\ntype SyncHandler interface { Handle(ctx context.Context, message Message) (Result, error) } type SyncHandlerAdapter struct { syncHandler SyncHandler } func (a SyncHandlerAdapter) Handle( ctx context.Context, message Message, returnResult ReturnResultFunc, ) error { result, err := a.syncHandler.Handle(ctx, message) if err != nil { return err } return returnResult(ctx, result) } Asynchronous handlers There are various techniques to wrap a remote procedure call in an asynchronous handler efficiently, e.g. a batch or a streaming API. I do not intend to cover the details here, but regardless of the implementations, the Handler interface allows the Handle method to return immediately without blocking the processing of the next message while a background goroutine can send the result back with the returnResult callback function when the result is ready later.\nA hybrid handler is also possible, returning the result immediately for some inputs while doing it asynchronously for others.\nWe might need to pay more attention to the error handling in the asynchronous handlers. The handler must ensure a result is returned so that the output can decrement the count correctly. So one possible way is to embed the error in the result to be passed back.\nConclusion In conclusion, the Hybrid Handler pattern allows synchronous and asynchronous handlers to coexist without incurring significant overhead, resulting in improved CPU utilization and reduced complexity. By implementing the Hybrid Handler pattern, developers can optimize performance in high-performance computing systems while maintaining the flexibility to handle various types of workloads.\n"},{
  "section": "Engineering",
  "slug": "/engineering/go-pattern-runner/",
  "title": "Go Pattern: Runner",
  "description": "",
  "date": "February 22, 2022",
  "image": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n  \n  \n    \n      \n    \n\n\n    \n    \n\n\n    \n    \n      \n      \n    \n    \n    \n\n\n    \n    \n      \n      \n        \n        \n        \n        \n        \n        \n\n\n        \n        \n\n\n        \u003cimg\n          \n            src=\"/images/engineering/covers/go-pattern-runner-cover_hu_30f9c2aab58884da.webp\" loading=\"lazy\" decoding=\"async\"\n          \n\n          alt=\"\"\n          class=\"  img\"\n          width=\"420\"\n          height=\"420\"\n          onerror=\"this.onerror='null';this.src='\\/images\\/engineering\\/covers\\/go-pattern-runner-cover_hu_6d2ac4e46470d7fb.png';\" /\u003e\n\n        \n      \n      \n    \n    \n  \n\n\n  \n",
  "imageSM": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n  \n  \n    \n      \n    \n\n\n    \n    \n\n\n    \n    \n      \n      \n    \n    \n    \n\n\n    \n    \n      \n      \n        \n        \n        \n        \n        \n        \n          \n          \n          \n          \n        \n\n\n        \n        \n\n\n        \u003cimg\n          \n            src=\"/images/engineering/covers/go-pattern-runner-cover_hu_11c1afa38732acdf.webp\" loading=\"lazy\" decoding=\"async\"\n          \n\n          alt=\"\"\n          class=\"  img\"\n          width=\"100\"\n          height=\"100\"\n          onerror=\"this.onerror='null';this.src='\\/images\\/engineering\\/covers\\/go-pattern-runner-cover_hu_3f32851f9d41f4.png';\" /\u003e\n\n        \n      \n      \n    \n    \n  \n\n\n  \n",
  "searchKeyword": "",
  "categories": "",
  "tags": "Go, pattern, runner",
  "content":"Again and again, a concurrent pattern emerges from the need to control goroutine lifecycles and handle their errors, and I call it the \u0026ldquo;Runner Pattern\u0026rdquo;.\nThe runner interface and its contract The pattern is as simple as a single-method interface:\n// Runner defines the Run method to be executed within a goroutine type Runner interface { Run(ctx context.Context) error } The contract of the interface covers two aspects.\nOn the goroutine lifecycle, the Run method will block until one of the following occurs:\nit completes successfully and returns nil it fails and returns an error it returns the context error as soon as the context gets cancelled On the error handling, The contract of a Runner also implies that:\nall the errors that need to be handled by the caller are returned by the Run method the Run method either can be called concurrently or returns an error if it cannot the Run method does not spawn its own goroutine directly unless there are nested Runners, whose errors need to be returned by the Run method too A group of runners To manage multiple runners as a group, it would be straightforward to implement a runner group as below, with some of the sync primitives like WaitGroup and Once (a reference implementation):\ntype Group interface { Go(r Runner) Wait() error } func NewGroup(ctx context.Context) Group With this simple group API, we could add multiple runners to a group and wait for all of them to complete. By default, Wait method returns the first error that occurred in any of the runners, or nil if all runners completed successfully.\nRationale Go\u0026rsquo;s CSP-style concurrency model enables us writing synchronous code intuitively but under the hood, schedules them off the thread when they block and resumes them when they unblock.\nWe should make full use of the unique ability of Go, controlling lifecycles and handling errors in an intuitively synchronous way rather than fighting against CSP and writing asynchronous-style code everywhere (e.g. callbacks, future/promise, async/await etc).\nWith the runner pattern, we abstracts away the boilerplate code of goroutine spawning and error handling, so that each piece of concurrent code can focus on its own business logic.\nIs that just an error group? The error group could be used to implement the runner pattern. In a sense, you could even call it an error group pattern. However, the runner pattern is more about the interface contract rather than the group implementation, and the contract is not only about error handling but also about the goroutine lifecycle.\nImplementation tips of a runner Here are a few tips to make a runner correct and efficient:\noptions, input/output channels and other dependencies can all be arguments passed into the constructor function of a runner a runner object should not contain any state mutable after initialisation, instead, mutable state and other resources should be scoped within the Run method the error handling logic of returning the first error can be overridden by handling a specific type of error within the Run method remember passing the context into wherever it is needed, and monitor if it gets cancelled, especially within loops all the resources allocated within the Run method must be released when it returns "},{
  "section": "Engineering",
  "slug": "/engineering/go-anti-patterns-parent-closer/",
  "title": "Go Anti-pattern: Parent Closer",
  "description": "",
  "date": "January 8, 2021",
  "image": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n  \n  \n    \n      \n    \n\n\n    \n    \n\n\n    \n    \n      \n      \n    \n    \n    \n\n\n    \n    \n      \n      \n        \n        \n        \n        \n        \n        \n\n\n        \n        \n\n\n        \u003cimg\n          \n            src=\"/images/engineering/covers/go-anti-patterns-parent-closer-cover_hu_86bceed4acb01f6d.webp\" loading=\"lazy\" decoding=\"async\"\n          \n\n          alt=\"\"\n          class=\"  img\"\n          width=\"420\"\n          height=\"420\"\n          onerror=\"this.onerror='null';this.src='\\/images\\/engineering\\/covers\\/go-anti-patterns-parent-closer-cover_hu_1c80834c3316fcdf.png';\" /\u003e\n\n        \n      \n      \n    \n    \n  \n\n\n  \n",
  "imageSM": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n  \n  \n    \n      \n    \n\n\n    \n    \n\n\n    \n    \n      \n      \n    \n    \n    \n\n\n    \n    \n      \n      \n        \n        \n        \n        \n        \n        \n          \n          \n          \n          \n        \n\n\n        \n        \n\n\n        \u003cimg\n          \n            src=\"/images/engineering/covers/go-anti-patterns-parent-closer-cover_hu_fdea6d736f10a73a.webp\" loading=\"lazy\" decoding=\"async\"\n          \n\n          alt=\"\"\n          class=\"  img\"\n          width=\"100\"\n          height=\"100\"\n          onerror=\"this.onerror='null';this.src='\\/images\\/engineering\\/covers\\/go-anti-patterns-parent-closer-cover_hu_32bf85cfefde9e4b.png';\" /\u003e\n\n        \n      \n      \n    \n    \n  \n\n\n  \n",
  "searchKeyword": "",
  "categories": "",
  "tags": "Go, pattern, anti-pattern, closer",
  "content":"Imagine you need to wrap multiple objects which implements io.Closer, e.g. three clients to fetch and combine data from different endpoints.\ntype Parent struct { child1 Child1 child2 Child2 child3 Child3 } Parent closer Let\u0026rsquo;s see how we can create and destroy a parent object.\nfunc NewParent() (*Parent, error) { child1, err := NewChild1() if err != nil { return nil, err } child2, err := NewChild1() if err != nil { // oops, child1 needs to be closed here child1.Close() return nil, err } child3, err := NewChild1() if err != nil { // oops again, both child1, and child2 needs to be closed here child1.Close() child2.Close() return nil, err } return \u0026amp;Parent{ child1: child1, child2: child2, child3: child3, }, nil } func (p *Parent) Close() error { var errs []error if err := p.child1.Close(); err != nil { errs = append(errs, err) } if err := p.child2.Close(); err != nil { errs = append(errs, err) } if err := p.child3.Close(); err != nil { errs = append(errs, err) } return multierr.Combine(errs...) } Note the boilerplate code of closing the children. Because the parent creates its children, it must be responsible for calling their Close method whenever needed. If there are any errors during the initialisation, the children already created have to be properly closed, and before the parent exits its scope, it has to close its children too.\nFurthermore, the Closer interface is contagious. If we organise our code by wrapping objects layer by layer like above, and any one of the descendants is a Closer, then all the types in the hierarchy are infected and have to implement the Closer interface too.\nParent container Unlike the parent closer, all of the complexity could have been avoided if the parent is a simple container, borrowing the references of the children rather than owning them, as long as the children outlive its parent.\nfunc NewParent(child1 Child1, child2 Child2, child3 Child3) *Parent { return \u0026amp;Parent{child1: child1, child2: child2, child3: child3} } func run() error { child1, err := NewChild1() if err != nil { return nil, err } defer child1.Close() child2, err := NewChild1() if err != nil { return nil, err } defer child2.Close() child3, err := NewChild1() if err != nil { return nil, err } defer child3.Close() parent := NewParent(child1, child2, child3) // the parent can be used safely here before func run returns } It is usually straightforward to guarantee the children outlive its parent in real cases:\neither the parent is created and held by a service during its whole lifetime, and func run could be a function that keeps running until the service terminates or the parent is created when handling a request, and func run is the request handler The key difference between a \u0026ldquo;parent closer\u0026rdquo; and a \u0026ldquo;parent container\u0026rdquo; is that the latter makes it possible to use the defer statements to close the children in either error or normal case, so the duplicated clean-up code can be avoided.\nConclusion io.Closer interfaces are contagious. Usually, we do not want to wrap them to make another io.Closer, instead, we should only wrap them by reference borrowing, without managing their lifetime within the wrapper.\n"},{
  "section": "Engineering",
  "slug": "/engineering/go-pattern-context-aware-lock/",
  "title": "Go Pattern: Context-aware Lock",
  "description": "",
  "date": "November 30, 2020",
  "image": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n  \n  \n    \n      \n    \n\n\n    \n    \n\n\n    \n    \n      \n      \n    \n    \n    \n\n\n    \n    \n      \n      \n        \n        \n        \n        \n        \n        \n\n\n        \n        \n\n\n        \u003cimg\n          \n            src=\"/images/engineering/covers/go-pattern-context-aware-lock-cover_hu_63e9a072469818e.webp\" loading=\"lazy\" decoding=\"async\"\n          \n\n          alt=\"\"\n          class=\"  img\"\n          width=\"420\"\n          height=\"420\"\n          onerror=\"this.onerror='null';this.src='\\/images\\/engineering\\/covers\\/go-pattern-context-aware-lock-cover_hu_1996db7812a80a00.png';\" /\u003e\n\n        \n      \n      \n    \n    \n  \n\n\n  \n",
  "imageSM": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n  \n  \n    \n      \n    \n\n\n    \n    \n\n\n    \n    \n      \n      \n    \n    \n    \n\n\n    \n    \n      \n      \n        \n        \n        \n        \n        \n        \n          \n          \n          \n          \n        \n\n\n        \n        \n\n\n        \u003cimg\n          \n            src=\"/images/engineering/covers/go-pattern-context-aware-lock-cover_hu_5e698ee2c8d566de.webp\" loading=\"lazy\" decoding=\"async\"\n          \n\n          alt=\"\"\n          class=\"  img\"\n          width=\"100\"\n          height=\"100\"\n          onerror=\"this.onerror='null';this.src='\\/images\\/engineering\\/covers\\/go-pattern-context-aware-lock-cover_hu_143408ce72909b4c.png';\" /\u003e\n\n        \n      \n      \n    \n    \n  \n\n\n  \n",
  "searchKeyword": "",
  "categories": "",
  "tags": "Go, pattern, context, lock, mutex",
  "content":"We often use Mutex or RWMutex as locks in Go, but sometimes we need a lock that can be cancelled by a context during the lock attempt.\nThe pattern is simple - we use a channel with length 1:\nlockChan := make(chan struct{}, 1) lockChan \u0026lt;- struct{}{} // lock \u0026lt;- lockChan // unlock When multiple goroutines try to obtain the lock, only one of them is able to fill into the only slot, and the rest are blocked until the slot is empty again after a readout.\nUnlike mutexes, we could easily cancel the lock attempt with a context:\nselect { case \u0026lt;-ctx.Done(): // cancelled case lockChan \u0026lt;- struct{}{}: // locked } Let\u0026rsquo;s wrap it up:\ntype CtxMutex struct { ch chan struct{} } func (mu *CtxMutex) Lock(ctx context.Context) bool { select { case \u0026lt;-ctx.Done(): return false case mu.ch \u0026lt;- struct{}{}: return true } } func (mu *CtxMutex) Unlock() { \u0026lt;- mu.ch } func (mu *CtxMutex) Locked() bool { return len(mu.ch) \u0026gt; 0 // locked or not } Further, context.WithTimeout could be used to apply a timeout to the lock.\n"},{
  "section": "Engineering",
  "slug": "/engineering/go-pattern-buffered-writer/",
  "title": "Go Pattern: Buffered Writer",
  "description": "",
  "date": "November 22, 2020",
  "image": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n  \n  \n    \n      \n    \n\n\n    \n    \n\n\n    \n    \n      \n      \n    \n    \n    \n\n\n    \n    \n      \n      \n        \n        \n        \n        \n        \n        \n\n\n        \n        \n\n\n        \u003cimg\n          \n            src=\"/images/engineering/covers/go-pattern-buffered-writer-cover_hu_6284f1d42b6eac73.webp\" loading=\"lazy\" decoding=\"async\"\n          \n\n          alt=\"\"\n          class=\"  img\"\n          width=\"420\"\n          height=\"420\"\n          onerror=\"this.onerror='null';this.src='\\/images\\/engineering\\/covers\\/go-pattern-buffered-writer-cover_hu_65f04e490a256408.png';\" /\u003e\n\n        \n      \n      \n    \n    \n  \n\n\n  \n",
  "imageSM": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n  \n  \n    \n      \n    \n\n\n    \n    \n\n\n    \n    \n      \n      \n    \n    \n    \n\n\n    \n    \n      \n      \n        \n        \n        \n        \n        \n        \n          \n          \n          \n          \n        \n\n\n        \n        \n\n\n        \u003cimg\n          \n            src=\"/images/engineering/covers/go-pattern-buffered-writer-cover_hu_a852e76f7dd56876.webp\" loading=\"lazy\" decoding=\"async\"\n          \n\n          alt=\"\"\n          class=\"  img\"\n          width=\"100\"\n          height=\"100\"\n          onerror=\"this.onerror='null';this.src='\\/images\\/engineering\\/covers\\/go-pattern-buffered-writer-cover_hu_f7dd71332ffa85f1.png';\" /\u003e\n\n        \n      \n      \n    \n    \n  \n\n\n  \n",
  "searchKeyword": "",
  "categories": "",
  "tags": "Go, pattern, buffered writer, batch, end-to-end principle, builder, unit of work",
  "content":"A buffered writer is so ubiquitous that we do not usually consider it as a pattern, but sometimes we reinvent it or even do it in an inferior way. Let us look at a real use case first.\nBatch processor What would you do to improve the throughput of a service? The answer is short: batching.\nBy processing and sending in a batch of multiple items instead of a single item at a time, you are amortizing the network overhead from the request-response round trip among all the items in the batch.\nThen how would you design a client interface to do that batching?\nHow about this?\ntype BatchProcessor interface { Process(items []Item) error } It looks like a straightforward solution, but in reality, it introduces unnecessary complexity in both business logic and error handling.\nThe processing is often composed of multiple steps working on the items, e.g. transformations and encoding.\nitems -\u0026gt; transformations -\u0026gt; encoding -\u0026gt; bytes With a batch processor interface like above, each step has to loop around the items, and each step has to deal with the errors from multiple items. Not only there is more complexity but also less flexibility. What if the client would like to send the rest of the items, even if some of the items return errors? What if the client instead would like to discard the whole batch if any one of them is erroneous?\nThere must be a better way.\nEnd-to-end principle \u0026ldquo;Smart terminals, dumb network\u0026rdquo;. The end-to-end (e2e) principle, articulated in the field of computer network, basically says any smart features should reside in the communicating end nodes, rather than in intermediary nodes.\nIn our use case, the smart feature is batching. By e2e, we make sure each step should only process a single item, and only the initial sender and the final receiver knows about the batching.\nThere are various examples In Go\u0026rsquo;s standard packages that already do this, e.g. bufio.Writer. The basic idea is an interface similar to below:\ntype BufferedWriter interface { Write(item Item) error Flush() error } The caller issues multiple writes to make a batch and a flush to mark the end of the batch. The writer chains the transformation and encoding steps of an item in a single write method and returns the error for the item. When the flush method is called, the writer flushes the whole batch and completes the batch.\nStateless vs Stateful On the surface, BatchProcessor is stateless while BufferedWriter is stateful, but the former only pushes to its caller the responsibility of aggregating a batch, which is a stateful operation. On the other hand, the final step of the processing - the underlying driver regardless it is of file or network IO - is stateful too. So BufferedWriter does not add additional burden to its caller for managing a stateful interface.\nRather, BufferedWriter not only simplifies the chain of processing within it, but also simplifies the batching logic on its caller side.\nConcurrency A BufferedWriter can become concurrently safe by locking both Write and Flush methods. However, the ideal way of calling a BufferedWriter is from a single goroutine so that the caller is able to control exactly what are in the batch, and we can get rid of the overhead of the lock.\nIf multiple goroutines must share a single underlying writer and at the same time want to control its own batches, then we could return an object instead of flushing, as below:\ntype Builder interface { Write(item Item) error Bytes() []byte // return bytes Object() Batch // or a batch object } In fact, it becomes the Builder Pattern. Each goroutine has its own builder, building its own batches, and then sending those batches to a shared driver.\nIn addition, we could even have various write methods, each for its own item type.\nTransaction If the caller needs to discard a batch, we could extend it with a rollback method, similar to sql.Tx:\ntype TxWriter interface { Write(item Item) error Commit() error Rollback() error } Then it becomes the Unit of Work Pattern.\nConclusion Whenever we want to process and send multiple items, consider this Buffered Writer Pattern and its variants and see if it can better suit our needs.\n"},{
  "section": "Engineering",
  "slug": "/engineering/value-vs-pointer-receivers/",
  "title": "Value vs Pointer Receivers",
  "description": "",
  "date": "June 19, 2020",
  "image": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n  \n  \n    \n      \n    \n\n\n    \n    \n\n\n    \n    \n      \n      \n    \n    \n    \n\n\n    \n    \n      \n      \n        \n        \n        \n        \n        \n        \n\n\n        \n        \n\n\n        \u003cimg\n          \n            src=\"/images/engineering/covers/value-vs-pointer-receivers-cover_hu_cfe922c6d0a4c045.webp\" loading=\"lazy\" decoding=\"async\"\n          \n\n          alt=\"\"\n          class=\"  img\"\n          width=\"420\"\n          height=\"420\"\n          onerror=\"this.onerror='null';this.src='\\/images\\/engineering\\/covers\\/value-vs-pointer-receivers-cover_hu_6fb9c512a06bba9f.png';\" /\u003e\n\n        \n      \n      \n    \n    \n  \n\n\n  \n",
  "imageSM": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n  \n  \n    \n      \n    \n\n\n    \n    \n\n\n    \n    \n      \n      \n    \n    \n    \n\n\n    \n    \n      \n      \n        \n        \n        \n        \n        \n        \n          \n          \n          \n          \n        \n\n\n        \n        \n\n\n        \u003cimg\n          \n            src=\"/images/engineering/covers/value-vs-pointer-receivers-cover_hu_410eb127e5932032.webp\" loading=\"lazy\" decoding=\"async\"\n          \n\n          alt=\"\"\n          class=\"  img\"\n          width=\"100\"\n          height=\"100\"\n          onerror=\"this.onerror='null';this.src='\\/images\\/engineering\\/covers\\/value-vs-pointer-receivers-cover_hu_de101f510f15ee55.png';\" /\u003e\n\n        \n      \n      \n    \n    \n  \n\n\n  \n",
  "searchKeyword": "",
  "categories": "",
  "tags": "Go, Receivers, Value, Pointer, Benchmark",
  "content":"Should I use value receivers or pointer receivers?\nValue receivers have some benefits include immutability, concurrent safety and clean logic (not always, often true). But to what extend can I use value receivers without an issue or performance penalty?\nIn the Go FAQ, there are 3 rules:\nmost important, does the method need to modify the receiver? If it does, the receiver must be a pointer if the receiver is large, a big struct for instance, it will be much cheaper to use a pointer receiver if some of the methods of the type must have pointer receivers, the rest should too, so the method set is consistent regardless of how the type is used Let\u0026rsquo;s look at rule 1. In many cases, an object needs to be modified by a method after its initialization, but it doesn’t mean the modification has to be done in place, an alternative and often a better way is to get a modified copy of the object, which is usually called a Fluent Interface. Basically it means a method with a value receiver and a return value of the same type. It’s just pure (no side effect) functional programming style under another name.\nThen rule 2 tells us to choose based on the struct size, but how big is a big struct? We know that time.Time is 3-words large with value receivers, but how about 4-words, 5-words or bigger structs? To answer this question, I did some benchmarks.\nThe benchmarks are based on the idea that a type with value receivers would need to implement fluent interface, so it should compare the performance between two fluent methods with value and pointer receivers:\nfunc (s S) ByValue() S { // ... return s } func (s *S) ByPointer() *S { // ... return s } It turned out inlining is critical to the overhead of value copying.\nWhen inlining is disabled (gcflags=-l), for a struct of 1 word, value receiver has the same performance as the pointer receiver, but for structs larger than 2 words, value receivers begin to show more and more overhead.\nHowever, when inlining is enabled (the default option), value receivers have almost the same performance as pointer receivers for struct size from 1 up to 9 words! Overhead of value copying starts to rise for structs of 10 words or more.\nThese results were tested on a Macbook Pro with go1.14.3.\nConclusion From the benchmark results, value receivers should be preferred if the methods are inlined and the struct size is equal to or smaller than 9 words (1 word == 64 bit), but this might not be the end of the story, the more complex a method is, the less likely it is inlined, but also the less proportion the copying overhead to the whole method logic. The overhead of copying from a value receiver might not be significant to the overall running time, so at the end of the day, the choice depends on the frequency of the method calls, the business logic and the performance requirements. When in doubt, benchmark it!\n"}]
